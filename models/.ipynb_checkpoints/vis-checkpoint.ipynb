{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/lustre/yslan/Repo/NVS/Projects/self-mono-sf/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('models')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules_sceneflow import WarpingLayer_SF, WarpingLayer_Flow\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "from ..utils_misc import (\n",
    "    flow_to_png_middlebury,\n",
    "    read_png_flow,\n",
    "    read_png_depth,\n",
    "    numpy2torch,\n",
    "    pixel2pts_ms,\n",
    "    get_pixelgrid,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warping_layer_sf = WarpingLayer_SF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp /= 256\n",
    "\n",
    "def load_sf_png(filename):\n",
    "    sf = io.imread(filename)\n",
    "    return sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_exp = '/mnt/lustre/yslan/Repo/NVS/Projects/self-mono-sf/eval/monosf_selfsup_kitti_test/flow/000000_10.png'\n",
    "sf_array = load_sf_png(sf_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+00, -7.5000e-01],\n",
       "        [-5.0000e-01, -7.5000e-01],\n",
       "        [-1.4901e-08, -7.5000e-01],\n",
       "        [ 5.0000e-01, -7.5000e-01]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "theta = torch.tensor([\n",
    "    [1,0,-0.25],\n",
    "    [0,1,0]\n",
    "], dtype=torch.float)\n",
    "grid = F.affine_grid(theta.unsqueeze(0), [1, 5, 4,4])\n",
    "# output = F.grid_sample(img_torch.unsqueeze(0), grid)\n",
    "grid[0][0]\n",
    "# grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warping_demo(img_idx, image_dir, results_dir, tt=None):\n",
    "\n",
    "    idx_curr = \"%06d\" % (img_idx)\n",
    "\n",
    "    im1_np0 = (\n",
    "        io.imread(os.path.join(image_dir, \"image_2/\" + idx_curr + \"_10.png\"))\n",
    "        / np.float32(255.0)\n",
    "    )[110:, :, :]\n",
    "    flo_f_np0 = read_png_flow(os.path.join(result_dir, \"flow/\" + idx_curr + \"_10.png\"))[\n",
    "        110:, :, :\n",
    "    ]\n",
    "    disp1_np0 = read_png_depth(\n",
    "        os.path.join(result_dir, \"disp_0/\" + idx_curr + \"_10.png\")\n",
    "    )[110:, :, :]\n",
    "    disp2_np0 = read_png_depth(\n",
    "        os.path.join(result_dir, \"disp_1/\" + idx_curr + \"_10.png\")\n",
    "    )[110:, :, :]\n",
    "\n",
    "    im1 = numpy2torch(im1_np0).unsqueeze(0)\n",
    "    disp1 = numpy2torch(disp1_np0).unsqueeze(0)\n",
    "    disp_diff = numpy2torch(disp2_np0).unsqueeze(0)\n",
    "    flo_f = numpy2torch(flo_f_np0).unsqueeze(0)\n",
    "\n",
    "    _, _, hh, ww = im1.size()\n",
    "\n",
    "    ## Intrinsic\n",
    "    focal_length = width_to_focal[ww]\n",
    "    cx = cam_center_dict[ww][0]\n",
    "    cy = cam_center_dict[ww][1]\n",
    "\n",
    "    k1_np = np.array([[focal_length, 0, cx], [0, focal_length, cy], [0, 0, 1]])\n",
    "    k1 = numpy2torch(k1_np)\n",
    "\n",
    "    # pixel_grid\n",
    "    b, _, h, w = disp_diff.shape\n",
    "    pixel_grid = get_pixelgrid(b, h, w, flo_f)\n",
    "    x_warp = tf.grid_sampel(im1_np0, pixel_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixelgrid(b, h, w, flow=None, direction=\"forward\"):\n",
    "\n",
    "    # get heterogeneous coordinates pixel grid\n",
    "    \"\"\"generate heterogeneous coord pixel grid\n",
    "\n",
    "    Returns:\n",
    "        [torch.Tensor]: heterogenous coordinates pixel grid\n",
    "    \"\"\"\n",
    "    assert direction in [\"forward\", \"backward\"]\n",
    "    grid_h = torch.linspace(0.0, w - 1, w).view(1, 1, 1, w).expand(b, 1, h, w)\n",
    "    grid_v = torch.linspace(0.0, h - 1, h).view(1, 1, h, 1).expand(b, 1, h, w)\n",
    "    ones = torch.ones_like(grid_h)\n",
    "\n",
    "    if flow is None:\n",
    "        pixelgrid = (\n",
    "            torch.cat((grid_h, grid_v, ones), dim=1).float().requires_grad_(False)\n",
    "        )\n",
    "    else:\n",
    "        if direction == \"backward\":\n",
    "            flow = -flow\n",
    "        pixelgrid = (\n",
    "            torch.cat(\n",
    "                (grid_h + flow[:, 0:1, :, :], grid_v + flow[:, 1:2, :, :], ones), dim=1\n",
    "            )\n",
    "            .float()\n",
    "            .requires_grad_(False)\n",
    "        )\n",
    "\n",
    "    return pixelgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data_dir = \"../demo/demo_generator/kitti_img\"\n",
    "demo_res_dir = \"../demo/demo_generator/results\"\n",
    "# result_dir = './eval/monosf_selfsup_kitti_test/'\n",
    "\n",
    "img_idx = 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_png_flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-dcf8514c1dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarping_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-ce6aea8d3ff1>\u001b[0m in \u001b[0;36mwarping_demo\u001b[0;34m(img_idx, image_dir, results_dir, tt)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     )[110:, :, :]\n\u001b[0;32m----> 9\u001b[0;31m     flo_f_np0 = read_png_flow(os.path.join(result_dir, \"flow/\" + idx_curr + \"_10.png\"))[\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;36m110\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_png_flow' is not defined"
     ]
    }
   ],
   "source": [
    "warp_x = warping_demo(img_idx, demo_data_dir, result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
